# CLIP-like models

|  Name    |  Type    | Res. | (Zero-Shot) IN-1K acc. |
| :--- | :--- | :--: | :--: |
|  CLIP (OpenAI) [[code]](https://github.com/openai/CLIP) [[paper]](https://arxiv.org/abs/2103.00020)    | ViT-B/32 | 224px | ---- |
| | ViT-B/16 | 224px | ---- |
| | ViT-L/14 | 224px | ---- |
| | RN50 | 224px | ---- |
| | RN101 | 224px | ---- |
| | RN50x4 | 224px | ---- |
| | RN50x16 | 224px | ---- |
| | RN50x64 | 224px | ---- |
| | ViT-L/14@336px | 336px | ---- |
|  OpenCLIP [[code]](https://github.com/mlfoundations/open_clip) [[paper]](https://arxiv.org/abs/2212.07143) | ViT-B/32 | 256px | 72.8% |
| | ViT-B/16	|224px	|73.5%|
| | ViT-L/14	|224px	|75.3%|
| | ViT-H/14	|224px	|78.0%|
| | ViT-L/14	|224px	|79.2%|
| | ViT-G/14	|224px	|80.1%|
| | ViT-L/14	|224px	|75.5%|
| | ConvNext-Base	|256px |71.5%|
| | ConvNext-Large |320px |76.9%|
| | ConvNext-XXLarge |256px |79.5%|
|  EVA-CLIP [[code]](https://github.com/baaivision/EVA) [[paper]](https://arxiv.org/abs/2303.15389) | EVA01_CLIP_g_14_psz14_s11B | 256px | 78.5% |
|      |      |     |      |
